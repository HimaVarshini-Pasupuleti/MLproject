{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9HNFTR4pHMQhUlOe6PQPT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HimaVarshini-Pasupuleti/MLproject/blob/main/_ML_FinalProject_EDUNUTSHELL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci0Vrdcm-zx0",
        "outputId": "fbdf8d49-5f8d-4f66-b770-1600c33c2f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume - JD Match Score: 44.79 %\n",
            "❌ Candidate not shortlisted\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "resume_text = \"\"\"\n",
        "Experienced data analyst skilled in Python, Machine Learning,\n",
        "SQL, and Tableau. Worked on fraud detection and data visualization projects.\n",
        "\"\"\"\n",
        "\n",
        "job_description = \"\"\"\n",
        "We are hiring a Data Analyst proficient in Python, SQL, and Machine Learning.\n",
        "Experience with data visualization tools like Tableau is preferred.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "resume_clean = clean_text(resume_text)\n",
        "jd_clean = clean_text(job_description)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform([resume_clean, jd_clean])\n",
        "\n",
        "\n",
        "similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
        "score = round(similarity * 100, 2)\n",
        "\n",
        "\n",
        "print(\"Resume - JD Match Score:\", score, \"%\")\n",
        "\n",
        "if score >= 70:\n",
        "    print(\" Candidate shortlisted\")\n",
        "else:\n",
        "    print(\" Candidate not shortlisted\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "job_description = \"\"\"\n",
        "We are looking for a Data Analyst who is proficient in Python, SQL, and data visualization tools.\n",
        "Responsibilities include analyzing business data, building dashboards, and preparing reports.\n",
        "The candidate should have experience with Machine Learning, Pandas, and Power BI.\n",
        "Good communication skills and teamwork are essential.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "doc = nlp(job_description)\n",
        "\n",
        "# EXTRACT KEYWORDS / SKILLS\n",
        "skills = set()\n",
        "for chunk in doc.noun_chunks:\n",
        "    if len(chunk.text.split()) <= 3:   # short useful phrases\n",
        "        skills.add(chunk.text.lower())\n",
        "\n",
        "# EXTRACT RESPONSIBILITIES\n",
        "responsibilities = []\n",
        "for sent in doc.sents:\n",
        "    if sent.text.strip().lower().startswith((\"responsible\", \"responsibilities\", \"develop\", \"analyze\", \"manage\", \"create\", \"prepare\")):\n",
        "        responsibilities.append(sent.text.strip())\n",
        "\n",
        "\n",
        "print(\"=== Extracted Keywords / Skills ===\")\n",
        "print(skills)\n",
        "print(\"\\n=== Responsibilities ===\")\n",
        "for r in responsibilities:\n",
        "    print(\"-\", r)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-JS5uxn_jFY",
        "outputId": "90c5e733-f33a-4c55-a468-00f1afd44843"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Extracted Keywords / Skills ===\n",
            "{'the candidate', 'teamwork', 'reports', 'experience', 'building dashboards', 'pandas', 'responsibilities', 'python', 'good communication skills', 'business data', 'data visualization tools', 'a data analyst', 'sql', '\\nwe', 'who', 'power bi', 'machine learning'}\n",
            "\n",
            "=== Responsibilities ===\n",
            "- Responsibilities include analyzing business data, building dashboards, and preparing reports.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "resume_text = \"\"\"\n",
        "Experienced Data Analyst skilled in Python, SQL, Power BI, and Machine Learning.\n",
        "Worked on fraud detection and data visualization projects using pandas and matplotlib.\n",
        "\"\"\"\n",
        "\n",
        "job_description = \"\"\"\n",
        "Looking for a Data Analyst with experience in Python, SQL, Power BI, and data visualization.\n",
        "Should understand machine learning concepts and have strong analytical skills.\n",
        "\"\"\"\n",
        "\n",
        "resume_clean = clean_text(resume_text)\n",
        "jd_clean = clean_text(job_description)\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform([resume_clean, jd_clean])\n",
        "\n",
        "\n",
        "similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
        "score = round(similarity * 100, 2)\n",
        "\n",
        "\n",
        "print(\"Resume Match Score:\", score, \"%\")\n",
        "if score >= 70:\n",
        "    print(\" Shortlisted Resume\")\n",
        "else:\n",
        "    print(\" Not Shortlisted Resume\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRmZWazs_i7B",
        "outputId": "eed2cea0-ae56-401f-9c16-711a5283cfb6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume Match Score: 47.25 %\n",
            " Not Shortlisted Resume\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42be3c8a",
        "outputId": "cad5ada2-4294-40a9-ab2b-8e07a8a7bab1"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.50.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\\\s]', '', text)\n",
        "    text = re.sub(r'\\\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def extract_skills(text):\n",
        "    skills_list = ['python', 'java', 'sql', 'excel', 'machine learning',\n",
        "                   'data analysis', 'power bi', 'tableau', 'communication',\n",
        "                   'pandas', 'numpy', 'deep learning']\n",
        "    found = [skill for skill in skills_list if skill in text.lower()]\n",
        "    return found\n",
        "\n",
        "\n",
        "st.title(\" Simple Resume Matcher Dashboard\")\n",
        "\n",
        "jd_text = st.text_area(\"Paste Job Description Here\", height=150)\n",
        "\n",
        "uploaded_files = st.file_uploader(\"Upload Multiple Resumes (TXT files)\", type=[\"txt\"], accept_multiple_files=True)\n",
        "\n",
        "threshold = st.slider(\"Shortlist Threshold (%)\", 0, 100, 70)\n",
        "\n",
        "if st.button(\"Match Resumes\"):\n",
        "    if not jd_text or not uploaded_files:\n",
        "        st.warning(\"Please upload resumes and paste a job description.\")\n",
        "    else:\n",
        "        jd_clean = clean_text(jd_text)\n",
        "        resumes = []\n",
        "        names = []\n",
        "        skills_found = []\n",
        "\n",
        "        for f in uploaded_files:\n",
        "            text = f.read().decode(\"utf-8\", errors=\"ignore\")\n",
        "            clean_resume = clean_text(text)\n",
        "            skills = extract_skills(clean_resume)\n",
        "            resumes.append(clean_resume)\n",
        "            names.append(f.name)\n",
        "            skills_found.append(\", \".join(skills))\n",
        "\n",
        "        docs = [jd_clean] + resumes\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        vectors = vectorizer.fit_transform(docs)\n",
        "\n",
        "\n",
        "        jd_vec = vectors[0:1]\n",
        "        resume_vecs = vectors[1:]\n",
        "        similarities = cosine_similarity(resume_vecs, jd_vec).flatten()\n",
        "\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            \"Candidate Name\": names,\n",
        "            \"Extracted Skills\": skills_found,\n",
        "            \"Score (%)\": (similarities * 100).round(2),\n",
        "            \"Shortlisted\": [\" Yes\" if s*100 >= threshold else \" No\" for s in similarities]\n",
        "        })\n",
        "\n",
        "\n",
        "        df = df.sort_values(by=\"Score (%)\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "        st.subheader(\" Matching Results\")\n",
        "        st.dataframe(df)\n",
        "\n",
        "        st.subheader(\" Top Candidates\")\n",
        "        top_n = st.number_input(\"Select how many top candidates to view\", min_value=1, max_value=len(df), value=3)\n",
        "        st.table(df.head(top_n))\n",
        "\n",
        "\n",
        "        csv = df.to_csv(index=False).encode(\"utf-8\")\n",
        "        st.download_button(\"Download Results as CSV\", csv, \"results.csv\", \"text/csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr-B6wepBEDg",
        "outputId": "55d9daaf-d3b7-4169-e052-933001b497b1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-10-08 13:33:41.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.108 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.109 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.114 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.121 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.136 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.142 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.147 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.158 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.170 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.187 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.188 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.193 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.202 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.207 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.210 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.214 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.222 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.225 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.229 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.232 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.240 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.242 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.246 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.251 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 13:33:41.256 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    }
  ]
}